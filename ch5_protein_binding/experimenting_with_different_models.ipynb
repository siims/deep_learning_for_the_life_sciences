{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Experimenting with protein binding (deepchem chapter 5).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDXmIhYHc_93"
      },
      "source": [
        "## Install deepchem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nz_qCDCL8ij"
      },
      "source": [
        "### Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhZ3pQn7c54i",
        "outputId": "28c8e827-f9e9-462c-b0e3-506fc15658b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  3490    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3490  100  3490    0     0  18368      0 --:--:-- --:--:-- --:--:-- 18272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "python version: 3.6.9\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added omnia to channels\n",
            "added conda-forge to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnQXCr6pdFTB",
        "outputId": "56ddad45-6878-4e5f-c646-add75e97df40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "!pip install --pre deepchem-nightly==2.3.0\n",
        "import deepchem\n",
        "deepchem.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepchem-nightly==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/86/e83fe3a6c6e93643269cbd9fc28861b147ba9286ee227ed775834cd01e59/deepchem-nightly-2.3.0.tar.gz (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 286kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from deepchem-nightly==2.3.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepchem-nightly==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepchem-nightly==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepchem-nightly==2.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepchem-nightly==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem-nightly==2.3.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem-nightly==2.3.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem-nightly==2.3.0) (1.15.0)\n",
            "Building wheels for collected packages: deepchem-nightly\n",
            "  Building wheel for deepchem-nightly (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepchem-nightly: filename=deepchem_nightly-2.3.0-cp36-none-any.whl size=383675 sha256=4d041a9e55b3390db4b8e66f20c9afefb74562b2b4831a539b16a0927a990c6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4c/b9/91b0715869556df7c02a6e580f82c539b5b92aedd1dc91cf84\n",
            "Successfully built deepchem-nightly\n",
            "Installing collected packages: deepchem-nightly\n",
            "Successfully installed deepchem-nightly-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82ZLGcRtw_l7",
        "outputId": "f74d025c-85bd-4921-83e0-04080792ed11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import tensorflow\n",
        "\n",
        "\n",
        "device_name = tensorflow.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "tensorflow.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs6qpJmrL8jU"
      },
      "source": [
        "### Locally\n",
        "\n",
        "Follow instructions here to setup your conda env with deepchem: https://deepchem.readthedocs.io/en/latest/installation.html#conda-installation\n",
        "\n",
        "Additionally install requirements:\n",
        "\n",
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwr6yb6HZ7FD"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWHfkLbueWZ7"
      },
      "source": [
        "import itertools\n",
        "from dataclasses import dataclass\n",
        "from typing import Union, List, Tuple, NoReturn, Optional\n",
        "import random\n",
        "import os\n",
        "\n",
        "import deepchem as dc\n",
        "from deepchem.models import KerasModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "ROOT_DIR = \"/content/drive/My Drive/Colab Notebooks/deep learning for the life sciences/chapter_5_protein_binding\"\n",
        "DATA_DIR = os.path.join(ROOT_DIR, \"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfk4ZnVSQUHD"
      },
      "source": [
        "%env DEEPCHEM_DATA_DIR=/content/drive/My Drive/Colab Notebooks/deep learning for the life sciences/chapter_5_protein_binding/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEQAdcK9qma2"
      },
      "source": [
        "%env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALjOk6UtsJdH"
      },
      "source": [
        "import os\n",
        "os.environ['DEEPCHEM_DATA_DIR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X5JV_bWeFu8"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF2o-1CBOkWw"
      },
      "source": [
        "### Cached data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10vJTlOyOgDI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNF41XIvT_aV"
      },
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "print(os.listdir(DATA_DIR))\n",
        "print(os.listdir('/content/drive'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_01PfTuoO0ir"
      },
      "source": [
        "# for unmounting\n",
        "# from google.colab import drive\n",
        "# drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olDr0t7bebrT"
      },
      "source": [
        "pdbbind_tasks, pdbbind_datasets, transformers = dc.molnet.load_pdbbind(\n",
        "    featurizer=\"grid\", split=\"random\", subset=\"core\", data_dir=DATA_DIR, save_dir=os.path.join(DATA_DIR, \"from-pdbbind\"), split_seed=100, reload=True\n",
        ")\n",
        "train_dataset, valid_dataset, test_dataset = pdbbind_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li9b7xPBfEuu"
      },
      "source": [
        "@dataclass\n",
        "class OutputModel:\n",
        "    model: dc.models.MultitaskRegressor\n",
        "    layers: List[int]\n",
        "    dropout: Union[float, List[float]]\n",
        "    seed: int\n",
        "    train_score: Optional[float]\n",
        "    test_score: Optional[float]\n",
        "\n",
        "\n",
        "def create_model(\n",
        "    layer_sizes: List[int], dropouts: Union[float, List[float]], learning_rate: float = 0.0003\n",
        ") -> dc.models.MultitaskRegressor:\n",
        "    n_features = train_dataset.X.shape[1]\n",
        "    model = dc.models.MultitaskRegressor(\n",
        "        n_tasks=len(pdbbind_tasks),\n",
        "        n_features=n_features,\n",
        "        layer_sizes=layer_sizes,\n",
        "        dropouts=dropouts,\n",
        "        learning_rate=learning_rate,\n",
        "        model_dir=f\"{ROOT_DIR}/model_dumps/pdbbind_nn__{'-'.join(map(str, layer_sizes))}_dropout_{dropouts}_learningrate_{learning_rate}\",\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model: dc.models.MultitaskRegressor) -> Tuple[float, float]:\n",
        "    metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "    train_scores = model.evaluate(train_dataset, [metric], transformers)[\"pearson_r2_score\"]\n",
        "    test_scores = model.evaluate(test_dataset, [metric], transformers)[\"pearson_r2_score\"]\n",
        "    return train_scores, test_scores\n",
        "\n",
        "\n",
        "def visualize_model_output(model: OutputModel) -> NoReturn:\n",
        "    print(\n",
        "        f\"\"\"############################################################\n",
        "Visualizing {model.model.__class__.__name__} model\n",
        "  Training score: {model.train_score}\n",
        "  Test score: {model.test_score}\n",
        "  Hyperparameters: \n",
        "    Layers: {model.layers} \n",
        "    Dropout: {model.dropout}\n",
        "    Seed: {model.seed}\n",
        "\n",
        "Model summary:\n",
        "\"\"\")\n",
        "    model.model.model.summary()\n",
        "    print(\"############################################################\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB-I-yZhWF1G"
      },
      "source": [
        "layers_list = [\n",
        "    # [125, 62],\n",
        "    # [250, 125],\n",
        "    # [500, 250],\n",
        "    # [1000, 500],\n",
        "    # [2000, 1000],\n",
        "    # [4000, 2000],\n",
        "    [2000, 1000, 500, 250],\n",
        "]\n",
        "\n",
        "dropouts_list = [0.2, 0.5, 0.8]\n",
        "\n",
        "seeds = [0, 10, 100, 1000]\n",
        "\n",
        "hyperparameters = list(itertools.product(layers_list, dropouts_list, seeds))\n",
        "\n",
        "(layers_list, dropouts_list, seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GdPvMu7WuLG"
      },
      "source": [
        "nn_models = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vINhrq6WU2G"
      },
      "source": [
        "for i in tqdm(range(len(hyperparameters))):\n",
        "    if i < len(models):\n",
        "        continue\n",
        "    layers, dropout, seed = hyperparameters[i]\n",
        "    random.seed(seed)\n",
        "    model = create_model(layer_sizes=layers, dropouts=dropout)\n",
        "    model.fit(train_dataset, nb_epoch=50)\n",
        "    train_score, test_score = evaluate_model(model=model)\n",
        "    models.append(\n",
        "        OutputModel(\n",
        "            model=model,\n",
        "            layers=layers,\n",
        "            dropout=dropout,\n",
        "            seed=seed,\n",
        "            train_score=train_score,\n",
        "            test_score=test_score,\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4lIxOQvWfDW"
      },
      "source": [
        "for model in models:\n",
        "    visualize_model_output(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}